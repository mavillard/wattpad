{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Werewolf and vampire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stories_df = pd.read_csv('data/out/werewolf_vampire_stories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>chapter_id</th>\n",
       "      <th>chapter_index</th>\n",
       "      <th>chapter_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157305</td>\n",
       "      <td>1100896</td>\n",
       "      <td>0</td>\n",
       "      <td>'I packed whilst you were at school' she said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157305</td>\n",
       "      <td>1108308</td>\n",
       "      <td>1</td>\n",
       "      <td>'Ladies and Gentlemen, this is your captain sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157305</td>\n",
       "      <td>1131027</td>\n",
       "      <td>2</td>\n",
       "      <td>My father was still frowning but he seemed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157305</td>\n",
       "      <td>1157067</td>\n",
       "      <td>3</td>\n",
       "      <td>Bloody girl, why did she have to turn up...she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157305</td>\n",
       "      <td>1160601</td>\n",
       "      <td>4</td>\n",
       "      <td>Sam x I blushed and looked down... “Umm...well...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   story_id  chapter_id  chapter_index  \\\n",
       "0    157305     1100896              0   \n",
       "1    157305     1108308              1   \n",
       "2    157305     1131027              2   \n",
       "3    157305     1157067              3   \n",
       "4    157305     1160601              4   \n",
       "\n",
       "                                        chapter_text  \n",
       "0  'I packed whilst you were at school' she said ...  \n",
       "1  'Ladies and Gentlemen, this is your captain sp...  \n",
       "2  My father was still frowning but he seemed to ...  \n",
       "3  Bloody girl, why did she have to turn up...she...  \n",
       "4  Sam x I blushed and looked down... “Umm...well...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23978, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5869"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_df.story_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = stories_df.chapter_text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23978"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [d for d in data if d is not np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23972"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 43s, sys: 718 ms, total: 11min 44s\n",
      "Wall time: 11min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wordnet_word_synsets = {}\n",
    "for d in data:\n",
    "    for w in word_tokenize(d):\n",
    "        if w not in wordnet_word_synsets:\n",
    "            synsets = wn.synsets(w)\n",
    "            if synsets:\n",
    "                wordnet_word_synsets[w] = synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72321"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordnet_word_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 32s, sys: 152 ms, total: 6min 33s\n",
      "Wall time: 6min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = [' '.join([w for w in word_tokenize(d) if w in wordnet_word_synsets]) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [d for d in data if d.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23904"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topic(topic, feature_names, n_top_words):\n",
    "    return [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "\n",
    "def get_topics(model, feature_names, n_top_words):\n",
    "    topics = []\n",
    "    for topic in model.components_:\n",
    "        topics.append(get_topic(topic, feature_names, n_top_words))\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def print_topics(topics):\n",
    "#     for topic_idx, topic in enumerate(topics):\n",
    "#         print(\"Topic #%d:\" % (topic_idx + 1))\n",
    "#         print(\" \".join(topic))\n",
    "#         print()\n",
    "\n",
    "def print_topics(topics):\n",
    "    for topic_idx, (similariy, topic, n_topics) in enumerate(topics):\n",
    "        print(\"Topic #%d:\" % (topic_idx + 1))\n",
    "        print('SIMILARITY:', similariy, '. Discovered topics:', n_topics)\n",
    "        print(\" \".join(topic))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_words_similarity(w1, w2):\n",
    "    similarities = [0]\n",
    "    for syns1 in wordnet_word_synsets[w1]:\n",
    "        for syns2 in wordnet_word_synsets[w2]:\n",
    "            similarity = wn.wup_similarity(syns1, syns2) or 0\n",
    "            similarities.append(similarity)\n",
    "    return max(similarities)\n",
    "\n",
    "def word_list_similarity(ws):\n",
    "    similarities = []\n",
    "    for w1 in ws:\n",
    "        for w2 in ws:\n",
    "            if w1 != w2:\n",
    "                similarity = two_words_similarity(w1, w2)\n",
    "                similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "\n",
    "# def topic_list_similarity(ts):\n",
    "#     similarities = []\n",
    "#     for t in ts:\n",
    "#         similarity = word_list_similarity(t)\n",
    "#         similarities.append(similarity)\n",
    "#     return np.mean(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_FEATURES = 1000\n",
    "N_TOP_WORDS = 20\n",
    "MAX_TOPICS = 200\n",
    "MIN_TOPICS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_samples = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21h 31min, sys: 34min 42s, total: 22h 5min 42s\n",
      "Wall time: 3d 17h 45min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf_vectorizer = CountVectorizer(\n",
    "    max_df=0.95,\n",
    "    min_df=2,\n",
    "    max_features=N_FEATURES,\n",
    "    stop_words='english',\n",
    ")\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "lda_similarities = []\n",
    "for N_TOPICS in range(MIN_TOPICS, MAX_TOPICS + 1):\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_topics=N_TOPICS,\n",
    "        learning_method='online',\n",
    "        learning_offset=50.,\n",
    "        random_state=0,\n",
    "        n_jobs=4,\n",
    "    )\n",
    "    lda.fit(tf)\n",
    "    topics = get_topics(lda, tf_feature_names, N_TOP_WORDS)\n",
    "    similarities = [(word_list_similarity(topic), topic, len(topics)) for topic in topics]\n",
    "    lda_similarities.extend(similarities)\n",
    "lda_winners = sorted(lda_similarities, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/out/lda_winners.csv', 'w') as f:\n",
    "    for topic in lda_winners:\n",
    "        f.write('{}, {}, {}\\n'.format(topic[0], ' '.join(topic[1]), topic[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6722436207494797, car drive seat road park driving bag drove home ride house window door inside hand bags head street taking pick, 191'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}, {}, {}'.format(topic[0], ' '.join(topic[1]), topic[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in range(1, 201):\n",
    "    c+=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20100"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.67224362074947974,\n",
       " ['car',\n",
       "  'drive',\n",
       "  'seat',\n",
       "  'road',\n",
       "  'park',\n",
       "  'driving',\n",
       "  'bag',\n",
       "  'drove',\n",
       "  'home',\n",
       "  'ride',\n",
       "  'house',\n",
       "  'window',\n",
       "  'door',\n",
       "  'inside',\n",
       "  'hand',\n",
       "  'bags',\n",
       "  'head',\n",
       "  'street',\n",
       "  'taking',\n",
       "  'pick'],\n",
       " 191)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "SIMILARITY: 0.672243620749 . Discovered topics: 191\n",
      "car drive seat road park driving bag drove home ride house window door inside hand bags head street taking pick\n",
      "\n",
      "Topic #2:\n",
      "SIMILARITY: 0.664257033619 . Discovered topics: 182\n",
      "car drive house seat road driving drove home ride window door inside street way lot park pick bag look pull\n",
      "\n",
      "Topic #3:\n",
      "SIMILARITY: 0.653545993766 . Discovered topics: 105\n",
      "car house door home drive seat road driving drove ride window inside way street stairs bags outside open walk bag\n",
      "\n",
      "Topic #4:\n",
      "SIMILARITY: 0.646932983514 . Discovered topics: 160\n",
      "team ball park dream game play line hit won running playing run ready fast air throw shot right pass set\n",
      "\n",
      "Topic #5:\n",
      "SIMILARITY: 0.641080358938 . Discovered topics: 157\n",
      "game play ball playing hit played beat won shot line ready air face throw middle fun threw like set high\n",
      "\n",
      "Topic #6:\n",
      "SIMILARITY: 0.640201534732 . Discovered topics: 80\n",
      "box picture bags stairs closet open bag shoes pack till pull door doors walk steps turn lights putting reach upstairs\n",
      "\n",
      "Topic #7:\n",
      "SIMILARITY: 0.638689521572 . Discovered topics: 200\n",
      "car house door home drive seat room window road driving stairs ride walk drove open going inside bed bags clothes\n",
      "\n",
      "Topic #8:\n",
      "SIMILARITY: 0.637439404356 . Discovered topics: 100\n",
      "car door bag seat window drive road open inside house way box driving home building ride hand outside minutes street\n",
      "\n",
      "Topic #9:\n",
      "SIMILARITY: 0.636974660368 . Discovered topics: 56\n",
      "room door open floor bed table small window wall hall voice inside doors chair stairs eyes hallway glass kitchen head\n",
      "\n",
      "Topic #10:\n",
      "SIMILARITY: 0.633820506908 . Discovered topics: 155\n",
      "says say asks looks ask smiles walks head nods hand pulls smile starts walk laughs takes turns look hands gets\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda_winners[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.95,\n",
    "    min_df=2,\n",
    "    max_features=N_FEATURES,\n",
    "    stop_words='english',\n",
    ")\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "nmf_similarities = []\n",
    "for N_TOPICS in range(MIN_TOPICS, MAX_TOPICS + 1):\n",
    "    nmf = NMF(\n",
    "        n_components=N_TOPICS,\n",
    "        random_state=1,\n",
    "        alpha=.1,\n",
    "        l1_ratio=.5,\n",
    "    )\n",
    "    nmf.fit(tfidf)\n",
    "    topics = get_topics(nmf, tfidf_feature_names, N_TOP_WORDS)\n",
    "    similarities = [(word_list_similarity(topic), topic, len(topics)) for topic in topics]\n",
    "    nmf_similarities.extend(similarities)\n",
    "    \n",
    "    if N_TOPICS % 100 == 0:\n",
    "        print(N_TOPICS, datetime.now())\n",
    "    \n",
    "nmf_winners = sorted(nmf_similarities, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/out/nmf_winners.txt', 'w') as f:\n",
    "    for topic in nmf_winners:\n",
    "        f.write('{}, {}, {}\\n'.format(topic[0], ' '.join(topic[1]), topic[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topics(nmf_winners[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stories_df.to_csv('data/out/werewolf_vampire_stories.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
