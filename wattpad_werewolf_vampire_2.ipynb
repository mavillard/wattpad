{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Werewolf and vampire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stories_df = pd.read_csv('data/out/werewolf_vampire_stories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>chapter_id</th>\n",
       "      <th>chapter_index</th>\n",
       "      <th>chapter_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157305</td>\n",
       "      <td>1100896</td>\n",
       "      <td>0</td>\n",
       "      <td>'I packed whilst you were at school' she said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157305</td>\n",
       "      <td>1108308</td>\n",
       "      <td>1</td>\n",
       "      <td>'Ladies and Gentlemen, this is your captain sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157305</td>\n",
       "      <td>1131027</td>\n",
       "      <td>2</td>\n",
       "      <td>My father was still frowning but he seemed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157305</td>\n",
       "      <td>1157067</td>\n",
       "      <td>3</td>\n",
       "      <td>Bloody girl, why did she have to turn up...she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157305</td>\n",
       "      <td>1160601</td>\n",
       "      <td>4</td>\n",
       "      <td>Sam x I blushed and looked down... “Umm...well...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   story_id  chapter_id  chapter_index  \\\n",
       "0    157305     1100896              0   \n",
       "1    157305     1108308              1   \n",
       "2    157305     1131027              2   \n",
       "3    157305     1157067              3   \n",
       "4    157305     1160601              4   \n",
       "\n",
       "                                        chapter_text  \n",
       "0  'I packed whilst you were at school' she said ...  \n",
       "1  'Ladies and Gentlemen, this is your captain sp...  \n",
       "2  My father was still frowning but he seemed to ...  \n",
       "3  Bloody girl, why did she have to turn up...she...  \n",
       "4  Sam x I blushed and looked down... “Umm...well...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23978, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5869"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_df.story_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = stories_df.chapter_text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23978"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [d for d in data if d is not np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23972"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 43s, sys: 718 ms, total: 11min 44s\n",
      "Wall time: 11min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wordnet_word_synsets = {}\n",
    "for d in data:\n",
    "    for w in word_tokenize(d):\n",
    "        if w not in wordnet_word_synsets:\n",
    "            synsets = wn.synsets(w)\n",
    "            if synsets:\n",
    "                wordnet_word_synsets[w] = synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72321"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordnet_word_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 32s, sys: 152 ms, total: 6min 33s\n",
      "Wall time: 6min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = [' '.join([w for w in word_tokenize(d) if w in wordnet_word_synsets]) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [d for d in data if d.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23904"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topic(topic, feature_names, n_top_words):\n",
    "    return [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "\n",
    "def get_topics(model, feature_names, n_top_words):\n",
    "    topics = []\n",
    "    for topic in model.components_:\n",
    "        topics.append(get_topic(topic, feature_names, n_top_words))\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def print_topics(topics):\n",
    "#     for topic_idx, topic in enumerate(topics):\n",
    "#         print(\"Topic #%d:\" % (topic_idx + 1))\n",
    "#         print(\" \".join(topic))\n",
    "#         print()\n",
    "\n",
    "def print_topics(topics):\n",
    "    for topic_idx, (similariy, topic, n_topics) in enumerate(topics):\n",
    "        print(\"Topic #%d:\" % (topic_idx + 1))\n",
    "        print('SIMILARITY:', similariy, '. Discovered topics:', n_topics)\n",
    "        print(\" \".join(topic))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_words_similarity(w1, w2):\n",
    "    similarities = [0]\n",
    "    for syns1 in wordnet_word_synsets[w1]:\n",
    "        for syns2 in wordnet_word_synsets[w2]:\n",
    "            similarity = wn.wup_similarity(syns1, syns2) or 0\n",
    "            similarities.append(similarity)\n",
    "    return max(similarities)\n",
    "\n",
    "def word_list_similarity(ws):\n",
    "    similarities = []\n",
    "    for w1 in ws:\n",
    "        for w2 in ws:\n",
    "            if w1 != w2:\n",
    "                similarity = two_words_similarity(w1, w2)\n",
    "                similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "\n",
    "# def topic_list_similarity(ts):\n",
    "#     similarities = []\n",
    "#     for t in ts:\n",
    "#         similarity = word_list_similarity(t)\n",
    "#         similarities.append(similarity)\n",
    "#     return np.mean(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_FEATURES = 1000\n",
    "N_TOP_WORDS = 20\n",
    "MAX_TOPICS = 200\n",
    "MIN_TOPICS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_samples = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lda_similarities = []\n",
    "for N_TOPICS in range(MIN_TOPICS, MAX_TOPICS + 1):\n",
    "    tf_vectorizer = CountVectorizer(\n",
    "        max_df=0.95,\n",
    "        min_df=2,\n",
    "        max_features=N_FEATURES,\n",
    "        stop_words='english',\n",
    "    )\n",
    "    tf = tf_vectorizer.fit_transform(data_samples)\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_topics=N_TOPICS,\n",
    "        learning_method='online',\n",
    "        learning_offset=50.,\n",
    "        random_state=0,\n",
    "        n_jobs=4,\n",
    "    )\n",
    "    lda.fit(tf)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    topics = get_topics(lda, tf_feature_names, N_TOP_WORDS)\n",
    "    similarities = [(word_list_similarity(topic), topic, len(topics)) for topic in topics]\n",
    "    lda_similarities.extend(similarities)\n",
    "lda_winners = sorted(lda_similarities, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/out/lda_winners.txt', 'w') as f:\n",
    "    for topic in lda_winners:\n",
    "        f.write(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topics(lda_winners[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nmf_similarities = []\n",
    "for N_TOPICS in range(MIN_TOPICS, MAX_TOPICS + 1):\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        max_df=0.95,\n",
    "        min_df=2,\n",
    "        max_features=N_FEATURES,\n",
    "        stop_words='english',\n",
    "    )\n",
    "    tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "    nmf = NMF(\n",
    "        n_components=N_TOPICS,\n",
    "        random_state=1,\n",
    "        alpha=.1,\n",
    "        l1_ratio=.5,\n",
    "    )\n",
    "    nmf.fit(tfidf)\n",
    "    tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "    topics = get_topics(nmf, tfidf_feature_names, N_TOP_WORDS)\n",
    "    similarities = [(word_list_similarity(topic), topic, len(topics)) for topic in topics]\n",
    "    nmf_similarities.extend(similarities)\n",
    "nmf_winner = max(nmf_similarities, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf_winners = sorted(nmf_similarities, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/out/nmf_winners.txt', 'w') as f:\n",
    "    for topic in nmf_winners:\n",
    "        f.write(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topics(nmf_winners[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stories_df.to_csv('data/out/werewolf_vampire_stories.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
