{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wattpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('data/out/metadata.csv', converters={'story_tags': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>story_description</th>\n",
       "      <th>category_id</th>\n",
       "      <th>story_tags</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5881</td>\n",
       "      <td>Stuff that is not really important. Contains s...</td>\n",
       "      <td>10</td>\n",
       "      <td>{idea, jovenes, look, sam, badboy, really, sca...</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14620</td>\n",
       "      <td>18 year old Grace has way more responsibilitie...</td>\n",
       "      <td>10</td>\n",
       "      <td>{mother, white, book, sisters, arcanxo, ryan, ...</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15577</td>\n",
       "      <td>Can i Have This Dance? Nicki Alab  whom lives ...</td>\n",
       "      <td>10</td>\n",
       "      <td>{cute, scared, anger, day, knockedover, suspen...</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24019</td>\n",
       "      <td>Giselle knew what she wanted. She wanted the b...</td>\n",
       "      <td>19</td>\n",
       "      <td>{liv, giselle, braydon, axel, dream, brother, ...</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31450</td>\n",
       "      <td>From the popular anime show Yu Yu Hakusho come...</td>\n",
       "      <td>19</td>\n",
       "      <td>{myruki, world, youko, yuyuhakusho, spirit, yu...</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   story_id                                  story_description  category_id  \\\n",
       "0      5881  Stuff that is not really important. Contains s...           10   \n",
       "1     14620  18 year old Grace has way more responsibilitie...           10   \n",
       "2     15577  Can i Have This Dance? Nicki Alab  whom lives ...           10   \n",
       "3     24019  Giselle knew what she wanted. She wanted the b...           19   \n",
       "4     31450  From the popular anime show Yu Yu Hakusho come...           19   \n",
       "\n",
       "                                          story_tags category_name  \n",
       "0  {idea, jovenes, look, sam, badboy, really, sca...      Classics  \n",
       "1  {mother, white, book, sisters, arcanxo, ryan, ...      Classics  \n",
       "2  {cute, scared, anger, day, knockedover, suspen...      Classics  \n",
       "3  {liv, giselle, braydon, axel, dream, brother, ...        Random  \n",
       "4  {myruki, world, youko, yuyuhakusho, spirit, yu...        Random  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245851, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('data/out/sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>chapter_id</th>\n",
       "      <th>chapter_index</th>\n",
       "      <th>chapter_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>183814</td>\n",
       "      <td>0</td>\n",
       "      <td>We caught up on a lot of things that happened ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>184177</td>\n",
       "      <td>1</td>\n",
       "      <td>They split up to enclose around me.  Crap.  Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>184771</td>\n",
       "      <td>2</td>\n",
       "      <td>Where's Bing?  Why aren't any of your roommate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>185259</td>\n",
       "      <td>3</td>\n",
       "      <td>Question Vote (it really helps I know) Copyrig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>186546</td>\n",
       "      <td>4</td>\n",
       "      <td>I want to marry Miss, I need your blessing.  Y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   story_id  chapter_id  chapter_index  \\\n",
       "0        35      183814              0   \n",
       "1        35      184177              1   \n",
       "2        35      184771              2   \n",
       "3        35      185259              3   \n",
       "4        35      186546              4   \n",
       "\n",
       "                                        chapter_text  \n",
       "0  We caught up on a lot of things that happened ...  \n",
       "1  They split up to enclose around me.  Crap.  Wh...  \n",
       "2  Where's Bing?  Why aren't any of your roommate...  \n",
       "3  Question Vote (it really helps I know) Copyrig...  \n",
       "4  I want to marry Miss, I need your blessing.  Y...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.11 ms, sys: 0 ns, total: 2.11 ms\n",
      "Wall time: 1.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stories_df = pd.read_csv(\n",
    "    'data/src/stories.tsv',\n",
    "    sep='\\t',\n",
    "    names=['story_id', 'chapter_id', 'chapter_index', 'chapter_text'],\n",
    "    chunksize=CHUNK_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.io.parsers.TextFileReader"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stories_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "needs_df = pd.read_excel('data/src/maslow.xlsx')\n",
    "needs_df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PHYSIOLOGICAL</th>\n",
       "      <th>SAFETY</th>\n",
       "      <th>LOVE</th>\n",
       "      <th>ESTEEM</th>\n",
       "      <th>SELF_ACTUALIZATION</th>\n",
       "      <th>SELF_TRANSCENDENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food</td>\n",
       "      <td>freedom</td>\n",
       "      <td>love</td>\n",
       "      <td>esteem</td>\n",
       "      <td>write</td>\n",
       "      <td>volunteering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>water</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>community</td>\n",
       "      <td>evaluation</td>\n",
       "      <td>poetry</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>salt</td>\n",
       "      <td>safety</td>\n",
       "      <td>parents</td>\n",
       "      <td>respect</td>\n",
       "      <td>history</td>\n",
       "      <td>morality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sugar</td>\n",
       "      <td>stable</td>\n",
       "      <td>family</td>\n",
       "      <td>capacity</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>protein</td>\n",
       "      <td>sunniness</td>\n",
       "      <td>sex</td>\n",
       "      <td>achievement</td>\n",
       "      <td>culture</td>\n",
       "      <td>volunteering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PHYSIOLOGICAL      SAFETY       LOVE       ESTEEM SELF_ACTUALIZATION  \\\n",
       "0          food     freedom       love       esteem              write   \n",
       "1         water  philosophy  community   evaluation             poetry   \n",
       "2          salt      safety    parents      respect            history   \n",
       "3         sugar      stable     family     capacity         philosophy   \n",
       "4       protein   sunniness        sex  achievement            culture   \n",
       "\n",
       "  SELF_TRANSCENDENCE  \n",
       "0       volunteering  \n",
       "1               help  \n",
       "2           morality  \n",
       "3             ethics  \n",
       "4       volunteering  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHYSIOLOGICAL\n",
      "SAFETY\n",
      "LOVE\n",
      "ESTEEM\n",
      "SELF_ACTUALIZATION\n",
      "SELF_TRANSCENDENCE\n"
     ]
    }
   ],
   "source": [
    "for need in needs_df:\n",
    "    print(need)\n",
    "    words = needs_df[need].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_sss = wn.synsets('volunteering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('volunteer.v.01'), Synset('volunteer.v.02'), Synset('volunteer.v.03')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tell voluntarily\n",
      "1 agree freely\n",
      "2 do volunteer work\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(need_sss)):\n",
    "    print(i, need_sss[i].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_sss[2].hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_sss = wn.synsets('work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('work.n.01'),\n",
       " Synset('work.n.02'),\n",
       " Synset('employment.n.02'),\n",
       " Synset('study.n.02'),\n",
       " Synset('work.n.05'),\n",
       " Synset('workplace.n.01'),\n",
       " Synset('oeuvre.n.01'),\n",
       " Synset('work.v.01'),\n",
       " Synset('work.v.02'),\n",
       " Synset('work.v.03'),\n",
       " Synset('function.v.01'),\n",
       " Synset('work.v.05'),\n",
       " Synset('exercise.v.03'),\n",
       " Synset('make.v.36'),\n",
       " Synset('work.v.08'),\n",
       " Synset('work.v.09'),\n",
       " Synset('work.v.10'),\n",
       " Synset('bring.v.03'),\n",
       " Synset('work.v.12'),\n",
       " Synset('cultivate.v.02'),\n",
       " Synset('work.v.14'),\n",
       " Synset('influence.v.01'),\n",
       " Synset('work.v.16'),\n",
       " Synset('work.v.17'),\n",
       " Synset('work.v.18'),\n",
       " Synset('work.v.19'),\n",
       " Synset('shape.v.02'),\n",
       " Synset('work.v.21'),\n",
       " Synset('knead.v.01'),\n",
       " Synset('exploit.v.01'),\n",
       " Synset('solve.v.01'),\n",
       " Synset('ferment.v.03'),\n",
       " Synset('sour.v.01'),\n",
       " Synset('work.v.27')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 activity directed toward making or doing something\n",
      "1 a product produced or accomplished through the effort or activity or agency of a person or thing\n",
      "2 the occupation for which you are paid\n",
      "3 applying the mind to learning and understanding a subject (especially by reading)\n",
      "4 (physics) a manifestation of energy; the transfer of energy from one physical system to another expressed as the product of a force and the distance through which it moves a body in the direction of that force\n",
      "5 a place where work is done\n",
      "6 the total output of a writer or artist (or a substantial part of it)\n",
      "7 exert oneself by doing mental or physical work for a purpose or out of necessity\n",
      "8 be employed\n",
      "9 have an effect or outcome; often the one desired or expected\n",
      "10 perform as expected when applied\n",
      "11 shape, form, or improve a material\n",
      "12 give a workout to\n",
      "13 proceed along a path\n",
      "14 operate in a certain place, area, or specialty\n",
      "15 proceed towards a goal or along a path or through an activity\n",
      "16 move in an agitated manner\n",
      "17 cause to happen or to occur as a consequence\n",
      "18 cause to work\n",
      "19 prepare for crops\n",
      "20 behave in a certain way when handled\n",
      "21 have and exert influence or effect\n",
      "22 operate in or through\n",
      "23 cause to operate or function\n",
      "24 provoke or excite\n",
      "25 gratify and charm, usually in order to influence\n",
      "26 make something, usually for a specific function\n",
      "27 move into or onto\n",
      "28 make uniform\n",
      "29 use or manipulate to one's advantage\n",
      "30 find the solution to (a problem or question) or understand the meaning of\n",
      "31 cause to undergo fermentation\n",
      "32 go sour or spoil\n",
      "33 arrive at a certain condition through repeated motion\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(need_sss)):\n",
    "    print(i, need_sss[i].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_sss[2].hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('branch_water.n.01'),\n",
       " Synset('drinking_water.n.01'),\n",
       " Synset('spring_water.n.02')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_sss[5].hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Synset' object has no attribute 'lemma_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-1bd65247310c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneed_sss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyponyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Synset' object has no attribute 'lemma_name'"
     ]
    }
   ],
   "source": [
    "need_sss[0].hyponyms()[2].lemma_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-9731b04550a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvehicle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vehicle.n.01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtypesOfVehicles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvehicle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyponyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-101-9731b04550a9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvehicle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vehicle.n.01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtypesOfVehicles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvehicle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyponyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "vehicle = wn.synset('vehicle.n.01')\n",
    "typesOfVehicles = list(set([w for s in vehicle.closure(lambda s:s.hyponyms()) for w in s.lemma_names]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bumper_car.n.01')\n",
      "Synset('craft.n.02')\n",
      "Synset('military_vehicle.n.01')\n",
      "Synset('rocket.n.01')\n",
      "Synset('skibob.n.01')\n",
      "Synset('sled.n.01')\n",
      "Synset('steamroller.n.02')\n",
      "Synset('wheeled_vehicle.n.01')\n",
      "Synset('aircraft.n.01')\n",
      "Synset('hovercraft.n.01')\n",
      "Synset('landing_craft.n.01')\n",
      "Synset('spacecraft.n.01')\n",
      "Synset('vessel.n.02')\n",
      "Synset('caisson.n.02')\n",
      "Synset('half_track.n.01')\n",
      "Synset('humvee.n.01')\n",
      "Synset('personnel_carrier.n.01')\n",
      "Synset('picket.n.04')\n",
      "Synset('reconnaissance_vehicle.n.01')\n",
      "Synset('tank.n.01')\n",
      "Synset('technical.n.01')\n",
      "Synset('troop_carrier.n.01')\n",
      "Synset('warplane.n.01')\n",
      "Synset('warship.n.01')\n",
      "Synset('weapons_carrier.n.01')\n",
      "Synset('missile.n.01')\n",
      "Synset('multistage_rocket.n.01')\n",
      "Synset('test_rocket.n.01')\n",
      "Synset('bobsled.n.01')\n",
      "Synset('bobsled.n.02')\n",
      "Synset('dogsled.n.01')\n",
      "Synset('luge.n.01')\n",
      "Synset('pung.n.01')\n",
      "Synset('toboggan.n.01')\n",
      "Synset('baby_buggy.n.01')\n",
      "Synset('bicycle.n.01')\n",
      "Synset('boneshaker.n.01')\n",
      "Synset('car.n.02')\n",
      "Synset('handcart.n.01')\n",
      "Synset('horse-drawn_vehicle.n.01')\n",
      "Synset('motor_scooter.n.01')\n",
      "Synset('rolling_stock.n.01')\n",
      "Synset('scooter.n.02')\n",
      "Synset('self-propelled_vehicle.n.01')\n",
      "Synset('skateboard.n.01')\n",
      "Synset('trailer.n.04')\n",
      "Synset('tricycle.n.01')\n",
      "Synset('unicycle.n.01')\n",
      "Synset('wagon.n.01')\n",
      "Synset('wagon.n.04')\n",
      "Synset('welcome_wagon.n.01')\n",
      "Synset('bogy.n.01')\n",
      "Synset('cruise_missile.n.01')\n",
      "Synset('heavier-than-air_craft.n.01')\n",
      "Synset('lighter-than-air_craft.n.01')\n",
      "Synset('stealth_aircraft.n.01')\n",
      "Synset('lander.n.02')\n",
      "Synset('lunar_excursion_module.n.01')\n",
      "Synset('space_capsule.n.01')\n",
      "Synset('space_shuttle.n.01')\n",
      "Synset('starship.n.01')\n",
      "Synset('bareboat.n.01')\n",
      "Synset('boat.n.01')\n",
      "Synset('fishing_boat.n.01')\n",
      "Synset('galley.n.01')\n",
      "Synset('galley.n.02')\n",
      "Synset('iceboat.n.02')\n",
      "Synset('patrol_boat.n.01')\n",
      "Synset('sailing_vessel.n.01')\n",
      "Synset('ship.n.01')\n",
      "Synset('shrimper.n.01')\n",
      "Synset('weather_ship.n.01')\n",
      "Synset('yacht.n.01')\n",
      "Synset('picket_boat.n.01')\n",
      "Synset('picket_ship.n.01')\n",
      "Synset('panzer.n.01')\n",
      "Synset('troopship.n.01')\n",
      "Synset('bomber.n.01')\n",
      "Synset('fighter.n.02')\n",
      "Synset('reconnaissance_plane.n.01')\n",
      "Synset('aircraft_carrier.n.01')\n",
      "Synset('battleship.n.01')\n",
      "Synset('capital_ship.n.01')\n",
      "Synset('corvette.n.01')\n",
      "Synset('cruiser.n.02')\n",
      "Synset('destroyer.n.01')\n",
      "Synset('destroyer_escort.n.01')\n",
      "Synset('frigate.n.01')\n",
      "Synset('frigate.n.02')\n",
      "Synset('guard_ship.n.01')\n",
      "Synset('ironclad.n.01')\n",
      "Synset('man-of-war.n.01')\n",
      "Synset('privateer.n.02')\n",
      "Synset('sloop_of_war.n.01')\n",
      "Synset('submersible.n.02')\n",
      "Synset('surface_ship.n.01')\n",
      "Synset('three-decker.n.03')\n",
      "Synset('torpedo_boat.n.01')\n",
      "Synset('air-to-air_missile.n.01')\n",
      "Synset('air-to-ground_missile.n.01')\n",
      "Synset('ballistic_missile.n.01')\n",
      "Synset('guided_missile.n.01')\n",
      "Synset('heat-seeking_missile.n.01')\n",
      "Synset('sidewinder.n.02')\n",
      "Synset('sounding_rocket.n.01')\n",
      "Synset('bassinet.n.02')\n",
      "Synset('bicycle-built-for-two.n.01')\n",
      "Synset('mountain_bike.n.01')\n",
      "Synset('ordinary.n.04')\n",
      "Synset('push-bike.n.01')\n",
      "Synset('safety_bicycle.n.01')\n",
      "Synset('velocipede.n.01')\n",
      "Synset('baggage_car.n.01')\n",
      "Synset('cabin_car.n.01')\n",
      "Synset('club_car.n.01')\n",
      "Synset('freight_car.n.01')\n",
      "Synset('guard's_van.n.01')\n",
      "Synset('handcar.n.01')\n",
      "Synset('mail_car.n.01')\n",
      "Synset('passenger_car.n.01')\n",
      "Synset('slip_coach.n.01')\n",
      "Synset('tender.n.04')\n",
      "Synset('van.n.03')\n",
      "Synset('applecart.n.02')\n",
      "Synset('barrow.n.03')\n",
      "Synset('hand_truck.n.01')\n",
      "Synset('laundry_cart.n.01')\n",
      "Synset('serving_cart.n.01')\n",
      "Synset('shopping_cart.n.01')\n",
      "Synset('carriage.n.02')\n",
      "Synset('chariot.n.02')\n",
      "Synset('limber.n.01')\n",
      "Synset('sulky.n.01')\n",
      "Synset('armored_vehicle.n.01')\n",
      "Synset('carrier.n.02')\n",
      "Synset('forklift.n.01')\n",
      "Synset('locomotive.n.01')\n",
      "Synset('motor_vehicle.n.01')\n",
      "Synset('recreational_vehicle.n.01')\n",
      "Synset('streetcar.n.01')\n",
      "Synset('tracked_vehicle.n.01')\n",
      "Synset('tractor.n.01')\n",
      "Synset('camper_trailer.n.01')\n",
      "Synset('mobile_home.n.01')\n",
      "Synset('pedicab.n.01')\n",
      "Synset('bandwagon.n.02')\n",
      "Synset('cart.n.01')\n",
      "Synset('chuck_wagon.n.01')\n",
      "Synset('covered_wagon.n.01')\n",
      "Synset('ice_wagon.n.01')\n",
      "Synset('lorry.n.01')\n",
      "Synset('milk_wagon.n.01')\n",
      "Synset('tramcar.n.01')\n",
      "Synset('wain.n.03')\n",
      "Synset('water_wagon.n.01')\n",
      "Synset('airplane.n.01')\n",
      "Synset('autogiro.n.01')\n",
      "Synset('drone.n.04')\n",
      "Synset('glider.n.01')\n",
      "Synset('helicopter.n.01')\n",
      "Synset('orthopter.n.01')\n",
      "Synset('airship.n.01')\n",
      "Synset('balloon.n.01')\n",
      "Synset('stealth_bomber.n.01')\n",
      "Synset('stealth_fighter.n.01')\n",
      "Synset('ark.n.02')\n",
      "Synset('barge.n.01')\n",
      "Synset('bumboat.n.01')\n",
      "Synset('canal_boat.n.01')\n",
      "Synset('ferry.n.01')\n",
      "Synset('fireboat.n.01')\n",
      "Synset('gondola.n.02')\n",
      "Synset('guard_boat.n.01')\n",
      "Synset('gunboat.n.01')\n",
      "Synset('junk.n.02')\n",
      "Synset('longboat.n.01')\n",
      "Synset('lugger.n.01')\n",
      "Synset('mackinaw.n.03')\n",
      "Synset('mailboat.n.01')\n",
      "Synset('motorboat.n.01')\n",
      "Synset('pilot_boat.n.01')\n",
      "Synset('police_boat.n.01')\n",
      "Synset('punt.n.02')\n",
      "Synset('river_boat.n.01')\n",
      "Synset('scow.n.01')\n",
      "Synset('sea_boat.n.01')\n",
      "Synset('small_boat.n.01')\n",
      "Synset('steamboat.n.01')\n",
      "Synset('surfboat.n.01')\n",
      "Synset('tender.n.05')\n",
      "Synset('tugboat.n.01')\n",
      "Synset('trawler.n.02')\n",
      "Synset('trireme.n.01')\n",
      "Synset('bark.n.03')\n",
      "Synset('brig.n.01')\n",
      "Synset('brigantine.n.01')\n",
      "Synset('clipper.n.02')\n",
      "Synset('cutter.n.05')\n",
      "Synset('dhow.n.01')\n",
      "Synset('felucca.n.01')\n",
      "Synset('fore-and-after.n.01')\n",
      "Synset('galleon.n.01')\n",
      "Synset('indiaman.n.01')\n",
      "Synset('ketch.n.01')\n",
      "Synset('rigger.n.04')\n",
      "Synset('sailboat.n.01')\n",
      "Synset('schooner.n.02')\n",
      "Synset('sloop.n.01')\n",
      "Synset('smack.n.03')\n",
      "Synset('square-rigger.n.01')\n",
      "Synset('windjammer.n.01')\n",
      "Synset('yawl.n.02')\n",
      "Synset('abandoned_ship.n.01')\n",
      "Synset('blockade-runner.n.01')\n",
      "Synset('cargo_ship.n.01')\n",
      "Synset('flagship.n.02')\n",
      "Synset('gas-turbine_ship.n.01')\n",
      "Synset('hospital_ship.n.01')\n",
      "Synset('hulk.n.02')\n",
      "Synset('icebreaker.n.01')\n",
      "Synset('lightship.n.01')\n",
      "Synset('minelayer.n.01')\n",
      "Synset('minesweeper.n.01')\n",
      "Synset('nuclear-powered_ship.n.01')\n",
      "Synset('passenger_ship.n.01')\n",
      "Synset('pirate.n.03')\n",
      "Synset('school_ship.n.01')\n",
      "Synset('shipwreck.n.01')\n",
      "Synset('sister_ship.n.01')\n",
      "Synset('slave_ship.n.01')\n",
      "Synset('small_ship.n.01')\n",
      "Synset('steamer.n.03')\n",
      "Synset('tender.n.06')\n",
      "Synset('three-decker.n.02')\n",
      "Synset('transport_ship.n.01')\n",
      "Synset('treasure_ship.n.01')\n",
      "Synset('whaler.n.02')\n",
      "Synset('wreck.n.04')\n",
      "Synset('dive_bomber.n.01')\n",
      "Synset('interceptor.n.01')\n",
      "Synset('kamikaze.n.01')\n",
      "Synset('dreadnought.n.01')\n",
      "Synset('pocket_battleship.n.01')\n",
      "Synset('battle_cruiser.n.01')\n",
      "Synset('guided_missile_cruiser.n.01')\n",
      "Synset('tin_can.n.01')\n",
      "Synset('torpedo-boat_destroyer.n.01')\n",
      "Synset('guided_missile_frigate.n.01')\n",
      "Synset('sailing_warship.n.01')\n",
      "Synset('submarine.n.01')\n",
      "Synset('pt_boat.n.01')\n",
      "Synset('intercontinental_ballistic_missile.n.01')\n",
      "Synset('antiballistic_missile.n.01')\n",
      "Synset('buzz_bomb.n.01')\n",
      "Synset('exocet.n.01')\n",
      "Synset('space_probe.n.01')\n",
      "Synset('surface-to-air_missile.n.01')\n",
      "Synset('brilliant_pebble.n.01')\n",
      "Synset('stinger.n.03')\n",
      "Synset('boxcar.n.01')\n",
      "Synset('cattle_car.n.01')\n",
      "Synset('coal_car.n.01')\n",
      "Synset('flatcar.n.01')\n",
      "Synset('gondola_car.n.01')\n",
      "Synset('refrigerator_car.n.01')\n",
      "Synset('tank_car.n.01')\n",
      "Synset('dining_car.n.01')\n",
      "Synset('nonsmoker.n.02')\n",
      "Synset('parlor_car.n.01')\n",
      "Synset('pullman.n.01')\n",
      "Synset('sleeping_car.n.01')\n",
      "Synset('smoker.n.03')\n",
      "Synset('pastry_cart.n.01')\n",
      "Synset('tea_cart.n.01')\n",
      "Synset('barouche.n.01')\n",
      "Synset('brougham.n.01')\n",
      "Synset('buckboard.n.01')\n",
      "Synset('buggy.n.01')\n",
      "Synset('cab.n.02')\n",
      "Synset('caroche.n.01')\n",
      "Synset('chaise.n.02')\n",
      "Synset('chariot.n.01')\n",
      "Synset('clarence.n.01')\n",
      "Synset('coach.n.04')\n",
      "Synset('droshky.n.01')\n",
      "Synset('gharry.n.01')\n",
      "Synset('gig.n.05')\n",
      "Synset('hackney.n.01')\n",
      "Synset('hansom.n.01')\n",
      "Synset('landau.n.02')\n",
      "Synset('post_chaise.n.01')\n",
      "Synset('stanhope.n.01')\n",
      "Synset('surrey.n.02')\n",
      "Synset('trap.n.07')\n",
      "Synset('troika.n.01')\n",
      "Synset('armored_car.n.01')\n",
      "Synset('armored_car.n.02')\n",
      "Synset('armored_personnel_carrier.n.01')\n",
      "Synset('assault_gun.n.02')\n",
      "Synset('tank_destroyer.n.01')\n",
      "Synset('choo-choo.n.01')\n",
      "Synset('diesel_locomotive.n.01')\n",
      "Synset('dinky.n.01')\n",
      "Synset('electric_locomotive.n.01')\n",
      "Synset('iron_horse.n.01')\n",
      "Synset('pilot_engine.n.01')\n",
      "Synset('shunter.n.01')\n",
      "Synset('steam_locomotive.n.01')\n",
      "Synset('switch_engine.n.01')\n",
      "Synset('tank_engine.n.01')\n",
      "Synset('traction_engine.n.01')\n",
      "Synset('amphibian.n.01')\n",
      "Synset('bloodmobile.n.01')\n",
      "Synset('car.n.01')\n",
      "Synset('doodlebug.n.01')\n",
      "Synset('four-wheel_drive.n.01')\n",
      "Synset('go-kart.n.01')\n",
      "Synset('golfcart.n.01')\n",
      "Synset('hearse.n.01')\n",
      "Synset('motorcycle.n.01')\n",
      "Synset('snowplow.n.01')\n",
      "Synset('truck.n.01')\n",
      "Synset('camper.n.02')\n",
      "Synset('dune_buggy.n.01')\n",
      "Synset('horsecar.n.01')\n",
      "Synset('caterpillar.n.02')\n",
      "Synset('snowmobile.n.01')\n",
      "Synset('bulldozer.n.01')\n",
      "Synset('skidder.n.03')\n",
      "Synset('dogcart.n.01')\n",
      "Synset('dumpcart.n.01')\n",
      "Synset('horse_cart.n.01')\n",
      "Synset('jaunting_car.n.01')\n",
      "Synset('jinrikisha.n.01')\n",
      "Synset('oxcart.n.01')\n",
      "Synset('pony_cart.n.01')\n",
      "Synset('water_cart.n.01')\n",
      "Synset('airliner.n.01')\n",
      "Synset('amphibian.n.02')\n",
      "Synset('biplane.n.01')\n",
      "Synset('delta_wing.n.01')\n",
      "Synset('hangar_queen.n.01')\n",
      "Synset('jet.n.01')\n",
      "Synset('monoplane.n.01')\n",
      "Synset('multiengine_airplane.n.01')\n",
      "Synset('propeller_plane.n.01')\n",
      "Synset('seaplane.n.01')\n",
      "Synset('ski-plane.n.01')\n",
      "Synset('tanker_plane.n.01')\n",
      "Synset('hang_glider.n.02')\n",
      "Synset('cargo_helicopter.n.01')\n",
      "Synset('shuttle_helicopter.n.01')\n",
      "Synset('single-rotor_helicopter.n.01')\n",
      "Synset('skyhook.n.01')\n",
      "Synset('barrage_balloon.n.01')\n",
      "Synset('blimp.n.02')\n",
      "Synset('hot-air_balloon.n.01')\n",
      "Synset('meteorological_balloon.n.01')\n",
      "Synset('trial_balloon.n.02')\n",
      "Synset('dredger.n.01')\n",
      "Synset('houseboat.n.01')\n",
      "Synset('pontoon.n.01')\n",
      "Synset('scow.n.02')\n",
      "Synset('wherry.n.01')\n",
      "Synset('car-ferry.n.01')\n",
      "Synset('cabin_cruiser.n.01')\n",
      "Synset('launch.n.01')\n",
      "Synset('outboard_motorboat.n.01')\n",
      "Synset('speedboat.n.01')\n",
      "Synset('water_scooter.n.01')\n",
      "Synset('keelboat.n.01')\n",
      "Synset('showboat.n.01')\n",
      "Synset('lifeboat.n.01')\n",
      "Synset('whaleboat.n.01')\n",
      "Synset('canoe.n.01')\n",
      "Synset('cockleshell.n.01')\n",
      "Synset('coracle.n.01')\n",
      "Synset('dinghy.n.01')\n",
      "Synset('gig.n.01')\n",
      "Synset('racing_boat.n.01')\n",
      "Synset('skiff.n.01')\n",
      "Synset('yawl.n.01')\n",
      "Synset('gig.n.04')\n",
      "Synset('carrack.n.01')\n",
      "Synset('catamaran.n.01')\n",
      "Synset('catboat.n.01')\n",
      "Synset('sharpie.n.04')\n",
      "Synset('trimaran.n.01')\n",
      "Synset('sharpshooter.n.03')\n",
      "Synset('knockabout.n.01')\n",
      "Synset('raceabout.n.01')\n",
      "Synset('banana_boat.n.01')\n",
      "Synset('bottom.n.07')\n",
      "Synset('cattleship.n.01')\n",
      "Synset('container_ship.n.01')\n",
      "Synset('liberty_ship.n.01')\n",
      "Synset('oil_tanker.n.01')\n",
      "Synset('liner.n.04')\n",
      "Synset('corsair.n.02')\n",
      "Synset('paddle_steamer.n.01')\n",
      "Synset('tramp_steamer.n.01')\n",
      "Synset('factory_ship.n.01')\n",
      "Synset('attack_submarine.n.01')\n",
      "Synset('auxiliary_research_submarine.n.01')\n",
      "Synset('fleet_ballistic_missile_submarine.n.01')\n",
      "Synset('nautilus.n.01')\n",
      "Synset('minuteman.n.02')\n",
      "Synset('manpad.n.01')\n",
      "Synset('stockcar.n.01')\n",
      "Synset('stagecoach.n.01')\n",
      "Synset('four-wheeler.n.01')\n",
      "Synset('remise.n.01')\n",
      "Synset('diesel-electric_locomotive.n.01')\n",
      "Synset('diesel-hydraulic_locomotive.n.01')\n",
      "Synset('swamp_buggy.n.01')\n",
      "Synset('ambulance.n.01')\n",
      "Synset('beach_wagon.n.01')\n",
      "Synset('bus.n.04')\n",
      "Synset('cab.n.03')\n",
      "Synset('compact.n.03')\n",
      "Synset('convertible.n.01')\n",
      "Synset('coupe.n.01')\n",
      "Synset('cruiser.n.01')\n",
      "Synset('electric.n.01')\n",
      "Synset('gas_guzzler.n.01')\n",
      "Synset('hardtop.n.01')\n",
      "Synset('hatchback.n.01')\n",
      "Synset('horseless_carriage.n.01')\n",
      "Synset('hot_rod.n.01')\n",
      "Synset('jeep.n.01')\n",
      "Synset('limousine.n.01')\n",
      "Synset('loaner.n.02')\n",
      "Synset('minicar.n.01')\n",
      "Synset('minivan.n.01')\n",
      "Synset('model_t.n.01')\n",
      "Synset('pace_car.n.01')\n",
      "Synset('racer.n.02')\n",
      "Synset('roadster.n.01')\n",
      "Synset('sedan.n.01')\n",
      "Synset('sport_utility.n.01')\n",
      "Synset('sports_car.n.01')\n",
      "Synset('stanley_steamer.n.01')\n",
      "Synset('stock_car.n.01')\n",
      "Synset('subcompact.n.01')\n",
      "Synset('touring_car.n.01')\n",
      "Synset('used-car.n.01')\n",
      "Synset('minibike.n.01')\n",
      "Synset('trail_bike.n.01')\n",
      "Synset('dump_truck.n.01')\n",
      "Synset('fire_engine.n.01')\n",
      "Synset('garbage_truck.n.01')\n",
      "Synset('lorry.n.02')\n",
      "Synset('pickup.n.01')\n",
      "Synset('sound_truck.n.01')\n",
      "Synset('tow_truck.n.01')\n",
      "Synset('tractor.n.02')\n",
      "Synset('trailer_truck.n.01')\n",
      "Synset('transporter.n.01')\n",
      "Synset('van.n.05')\n",
      "Synset('van.n.04')\n",
      "Synset('sno-cat.n.01')\n",
      "Synset('angledozer.n.01')\n",
      "Synset('tumbrel.n.01')\n",
      "Synset('dray.n.01')\n",
      "Synset('watering_cart.n.01')\n",
      "Synset('airbus.n.01')\n",
      "Synset('narrowbody_aircraft.n.01')\n",
      "Synset('widebody_aircraft.n.01')\n",
      "Synset('fanjet.n.01')\n",
      "Synset('jetliner.n.01')\n",
      "Synset('jumbojet.n.01')\n",
      "Synset('twinjet.n.01')\n",
      "Synset('double-prop.n.01')\n",
      "Synset('propjet.n.01')\n",
      "Synset('single_prop.n.01')\n",
      "Synset('floatplane.n.01')\n",
      "Synset('flying_boat.n.01')\n",
      "Synset('kite_balloon.n.01')\n",
      "Synset('pilot_balloon.n.01')\n",
      "Synset('hydrofoil.n.02')\n",
      "Synset('birchbark_canoe.n.01')\n",
      "Synset('dugout_canoe.n.01')\n",
      "Synset('kayak.n.01')\n",
      "Synset('outrigger_canoe.n.01')\n",
      "Synset('rowing_boat.n.01')\n",
      "Synset('wherry.n.02')\n",
      "Synset('racing_gig.n.01')\n",
      "Synset('shell.n.07')\n",
      "Synset('sampan.n.01')\n",
      "Synset('jolly_boat.n.01')\n",
      "Synset('supertanker.n.01')\n",
      "Synset('cabin_liner.n.01')\n",
      "Synset('cargo_liner.n.01')\n",
      "Synset('cruise_ship.n.01')\n",
      "Synset('luxury_liner.n.01')\n",
      "Synset('side-wheeler.n.01')\n",
      "Synset('sternwheeler.n.01')\n",
      "Synset('funny_wagon.n.01')\n",
      "Synset('shooting_brake.n.01')\n",
      "Synset('gypsy_cab.n.01')\n",
      "Synset('minicab.n.01')\n",
      "Synset('panda_car.n.01')\n",
      "Synset('berlin.n.03')\n",
      "Synset('finisher.n.05')\n",
      "Synset('stock_car.n.02')\n",
      "Synset('brougham.n.02')\n",
      "Synset('moped.n.01')\n",
      "Synset('ladder_truck.n.01')\n",
      "Synset('tandem_trailer.n.01')\n",
      "Synset('bookmobile.n.01')\n",
      "Synset('delivery_truck.n.01')\n",
      "Synset('laundry_truck.n.01')\n",
      "Synset('milk_float.n.01')\n",
      "Synset('moving_van.n.01')\n",
      "Synset('passenger_van.n.01')\n",
      "Synset('police_van.n.01')\n",
      "Synset('racing_skiff.n.01')\n",
      "Synset('scull.n.03')\n",
      "Synset('pantechnicon.n.01')\n"
     ]
    }
   ],
   "source": [
    "for s in vehicle.closure(lambda s:s.hyponyms()):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_sss = wn.synsets('need')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('need.n.01'),\n",
       " Synset('need.n.02'),\n",
       " Synset('motivation.n.01'),\n",
       " Synset('indigence.n.01'),\n",
       " Synset('necessitate.v.01'),\n",
       " Synset('want.v.02'),\n",
       " Synset('need.v.03')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a condition requiring relief\n",
      "1 anything that is necessary but lacking\n",
      "2 the psychological feature that arouses an organism to action toward a desired goal; the reason for the action; that which gives purpose and direction to behavior\n",
      "3 a state of extreme poverty or destitution\n",
      "4 require as useful, just, or proper\n",
      "5 have need of\n",
      "6 have or feel a need for\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(need_sss)):\n",
    "    print(i, need_sss[i].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_ss = need_sss[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_lemmas = need_ss.lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['motivation', 'motive', 'need']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_hyponyms = need_ss.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('ethical_motive.n.01'),\n",
       " Synset('irrational_motive.n.01'),\n",
       " Synset('life.n.13'),\n",
       " Synset('psychic_energy.n.01'),\n",
       " Synset('rational_motive.n.01'),\n",
       " Synset('urge.n.01')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('conscience.n.01'),\n",
       " Synset('hedonism.n.01'),\n",
       " Synset('inner_light.n.01')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_hyponyms[0].hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_hyponyms_all = list(need_ss.closure(lambda x: x.hyponyms()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('eat.v.01') take in solid food\n",
      "Synset('eat.v.02') eat a meal; take a meal\n",
      "Synset('feed.v.06') take in food; used of animals only\n",
      "Synset('eat.v.04') worry or cause anxiety in a persistent way\n",
      "Synset('consume.v.05') use up (resources or materials)\n",
      "Synset('corrode.v.01') cause to deteriorate due to the action of water, air, or an acid\n"
     ]
    }
   ],
   "source": [
    "for x in wn.synsets('eat'):\n",
    "    print(x, x.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('food.n.01'), Synset('substance.n.07'), Synset('matter.n.03'), Synset('physical_entity.n.01'), Synset('entity.n.01')]\n",
      "[Synset('provide.v.02'), Synset('give.v.03'), Synset('transfer.v.05')]\n",
      "[Synset('provide.v.02'), Synset('give.v.03'), Synset('transfer.v.05')]\n",
      "[Synset('supply.v.01'), Synset('give.v.03'), Synset('transfer.v.05')]\n",
      "[Synset('insert.v.02'), Synset('put.v.01'), Synset('move.v.02')]\n",
      "[Synset('promote.v.01'), Synset('support.v.01')]\n",
      "[Synset('consume.v.02')]\n",
      "[Synset('provide.v.02'), Synset('give.v.03'), Synset('transfer.v.05')]\n",
      "[Synset('move.v.03')]\n",
      "[Synset('exploit.v.01'), Synset('use.v.01')]\n",
      "[Synset('regale.v.01'), Synset('provide.v.02'), Synset('give.v.03'), Synset('transfer.v.05')]\n",
      "[Synset('enrich.v.01'), Synset('better.v.02'), Synset('change.v.01')]\n",
      "[Synset('give.v.08')]\n"
     ]
    }
   ],
   "source": [
    "for x in wn.synsets('feed'):\n",
    "    hypers = list(x.closure(lambda x: x.hypernyms(), depth=-1))\n",
    "    print(hypers)\n",
    "    if need_ss in hypers:\n",
    "        print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('consume.v.02'), Synset('eat.v.02')]\n",
      "[Synset('consume.v.02')]\n",
      "[Synset('consume.v.02')]\n",
      "[Synset('worry.v.03')]\n",
      "[Synset('spend.v.02')]\n",
      "[Synset('damage.v.01')]\n"
     ]
    }
   ],
   "source": [
    "for x in wn.synsets('eat'):\n",
    "    hypers = list(x.closure(lambda x: x.hypernyms(), depth=1))\n",
    "    print(hypers)\n",
    "    if need_ss in hypers:\n",
    "        print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_ss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('ethical_motive.n.01'),\n",
       " Synset('irrational_motive.n.01'),\n",
       " Synset('life.n.13'),\n",
       " Synset('psychic_energy.n.01'),\n",
       " Synset('rational_motive.n.01'),\n",
       " Synset('urge.n.01'),\n",
       " Synset('conscience.n.01'),\n",
       " Synset('hedonism.n.01'),\n",
       " Synset('inner_light.n.01'),\n",
       " Synset('compulsion.n.02'),\n",
       " Synset('irrational_impulse.n.01'),\n",
       " Synset('mania.n.01'),\n",
       " Synset('incitement.n.03'),\n",
       " Synset('libidinal_energy.n.01'),\n",
       " Synset('disincentive.n.01'),\n",
       " Synset('incentive.n.01'),\n",
       " Synset('reason.n.01'),\n",
       " Synset('abience.n.01'),\n",
       " Synset('adience.n.01'),\n",
       " Synset('death_instinct.n.01'),\n",
       " Synset('wanderlust.n.01'),\n",
       " Synset('sense_of_shame.n.01'),\n",
       " Synset('superego.n.01'),\n",
       " Synset('wee_small_voice.n.01'),\n",
       " Synset('onomatomania.n.01'),\n",
       " Synset('compulsion.n.01'),\n",
       " Synset('agromania.n.01'),\n",
       " Synset('dipsomania.n.01'),\n",
       " Synset('egomania.n.01'),\n",
       " Synset('kleptomania.n.01'),\n",
       " Synset('logorrhea.n.01'),\n",
       " Synset('monomania.n.01'),\n",
       " Synset('necrophilia.n.01'),\n",
       " Synset('phaneromania.n.01'),\n",
       " Synset('pyromania.n.01'),\n",
       " Synset('trichotillomania.n.01'),\n",
       " Synset('signal.n.02'),\n",
       " Synset('acathexis.n.01'),\n",
       " Synset('cathexis.n.01'),\n",
       " Synset('moral_force.n.01'),\n",
       " Synset('occasion.n.03'),\n",
       " Synset('score.n.05'),\n",
       " Synset('why.n.01')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_hyponyms_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wattpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    for p in punctuation:\n",
    "        text = text.replace(p, '')\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window_generator(seq, size, step):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), step) if pos + step < len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hands', 'across', 'hawthorne', 'rally', 'held', 'ha']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"\"\"\n",
    "Hands Across Hawthorne was a rally held at the Hawthorne Bridge in the American West Coast city of Portland, Oregon, on May 29, 2011. The demonstration was in response to an attack, one week earlier, on Brad Forkner and Christopher Rosevear, a gay male couple who had been holding hands while walking across the bridge. According to the couple and the Portland Police Bureau, a group of five men followed Forkner and Rosevear along the bridge before physically assaulting them. The assault was condemned by Portland's mayor, Sam Adams, and its police chief, Mike Reese, and news of the attack spread throughout the Pacific Northwest and the United States. The attack prompted volunteers from the Q Center, a nonprofit organization that supports the LGBT community, to form street patrols as a means of monitoring Portland's downtown area.\n",
    "Several LGBT and human rights organizations sponsored Hands Across Hawthorne in response to the attack, with the purpose of linking hands across the entire span of the Hawthorne Bridge to show solidarity. More than 4,000 people attended the rally, which had been publicized on a single Facebook page 72 hours previously. Forkner, Rosevear, Mayor Adams, and other community leaders spoke at the rally. The event received attention throughout the United States. On June 5, residents of Spokane, Washington, held a similar hand-holding rally called \"Hands Across Monroe\", crossing the Monroe Street Bridge in Riverfront Park.\n",
    "\"\"\"\n",
    "\n",
    "def extract_information(text, window_size=50, step=25):\n",
    "    info = {\n",
    "        'needs': None, # LDA diciendole lo que tiene que encontrar\n",
    "        'behaviours': None, \n",
    "    }\n",
    "    text = clean_text(text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [w for w in words if w not in stopwords.words('english')]\n",
    "    windows = window_generator(words, window_size, step)\n",
    "#     for window in windows:\n",
    "        \n",
    "    return list(windows)\n",
    "   \n",
    "extract_information(example[:50], 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['el', 'aliento', 'de', 'mi', 'gato', 'huele', 'comida', 'de', 'gato']]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example=\"El aliento de mi gato huele a comida de gato\"\n",
    "extract_information(example, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hands Across Hawthorne was a rally held at the Hawthorne Bridge in the American\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['hands',\n",
       "  'across',\n",
       "  'hawthorne',\n",
       "  'rally',\n",
       "  'held',\n",
       "  'hawthorne',\n",
       "  'bridge',\n",
       "  'american'],\n",
       " ['hawthorne', 'bridge', 'american']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = ' '.join(example.split()[:14])\n",
    "print(ex)\n",
    "extract_information(ex, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA topic extraction, guiding the process with our specific keywords\n",
    "# Result: topic list, list of words and frequencies\n",
    "needs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Graph\n",
    "behaviors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/antonio/.virtualenvs/wattpad/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antonio/.virtualenvs/wattpad/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mget_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antonio/.virtualenvs/wattpad/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    980\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antonio/.virtualenvs/wattpad/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1717\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas/_libs/parsers.c:10862)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas/_libs/parsers.c:11343)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas/_libs/parsers.c:11884)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows (pandas/_libs/parsers.c:11755)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error (pandas/_libs/parsers.c:28765)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for chunk in stories_df:\n",
    "    for text in chunk.chapter_text:\n",
    "        text = clean_text(text)\n",
    "        words = word_tokenize(text)\n",
    "        words = [w for w in words if w not in stopwords.words('english')]\n",
    "        windows = window_generator(words, window_size, step)\n",
    "        for window in windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984493"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c=0\n",
    "# for chunk in stories_df:\n",
    "#     for i, x in chunk.iterrows():\n",
    "#         c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3947664"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c\n",
    "# 3947664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# c=0\n",
    "# for chunk in stories_df:\n",
    "#     if c > 0:\n",
    "#         break\n",
    "#     display(chunk)\n",
    "#     c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Comprobar que pasa si el texto es menor que el window_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
