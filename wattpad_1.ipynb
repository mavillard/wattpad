{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wattpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('data/out/metadata.csv', converters={'story_tags': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>story_description</th>\n",
       "      <th>category_id</th>\n",
       "      <th>story_tags</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5881</td>\n",
       "      <td>Stuff that is not really important. Contains s...</td>\n",
       "      <td>10</td>\n",
       "      <td>{idea, jovenes, look, sam, badboy, really, sca...</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14620</td>\n",
       "      <td>18 year old Grace has way more responsibilitie...</td>\n",
       "      <td>10</td>\n",
       "      <td>{mother, white, book, sisters, arcanxo, ryan, ...</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15577</td>\n",
       "      <td>Can i Have This Dance? Nicki Alab  whom lives ...</td>\n",
       "      <td>10</td>\n",
       "      <td>{cute, scared, anger, day, knockedover, suspen...</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24019</td>\n",
       "      <td>Giselle knew what she wanted. She wanted the b...</td>\n",
       "      <td>19</td>\n",
       "      <td>{liv, giselle, braydon, axel, dream, brother, ...</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31450</td>\n",
       "      <td>From the popular anime show Yu Yu Hakusho come...</td>\n",
       "      <td>19</td>\n",
       "      <td>{myruki, world, youko, yuyuhakusho, spirit, yu...</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   story_id                                  story_description  category_id  \\\n",
       "0      5881  Stuff that is not really important. Contains s...           10   \n",
       "1     14620  18 year old Grace has way more responsibilitie...           10   \n",
       "2     15577  Can i Have This Dance? Nicki Alab  whom lives ...           10   \n",
       "3     24019  Giselle knew what she wanted. She wanted the b...           19   \n",
       "4     31450  From the popular anime show Yu Yu Hakusho come...           19   \n",
       "\n",
       "                                          story_tags category_name  \n",
       "0  {idea, jovenes, look, sam, badboy, really, sca...      Classics  \n",
       "1  {mother, white, book, sisters, arcanxo, ryan, ...      Classics  \n",
       "2  {cute, scared, anger, day, knockedover, suspen...      Classics  \n",
       "3  {liv, giselle, braydon, axel, dream, brother, ...        Random  \n",
       "4  {myruki, world, youko, yuyuhakusho, spirit, yu...        Random  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245851, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('data/out/sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>chapter_id</th>\n",
       "      <th>chapter_index</th>\n",
       "      <th>chapter_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>183814</td>\n",
       "      <td>0</td>\n",
       "      <td>We caught up on a lot of things that happened ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>184177</td>\n",
       "      <td>1</td>\n",
       "      <td>They split up to enclose around me.  Crap.  Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>184771</td>\n",
       "      <td>2</td>\n",
       "      <td>Where's Bing?  Why aren't any of your roommate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>185259</td>\n",
       "      <td>3</td>\n",
       "      <td>Question Vote (it really helps I know) Copyrig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>186546</td>\n",
       "      <td>4</td>\n",
       "      <td>I want to marry Miss, I need your blessing.  Y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   story_id  chapter_id  chapter_index  \\\n",
       "0        35      183814              0   \n",
       "1        35      184177              1   \n",
       "2        35      184771              2   \n",
       "3        35      185259              3   \n",
       "4        35      186546              4   \n",
       "\n",
       "                                        chapter_text  \n",
       "0  We caught up on a lot of things that happened ...  \n",
       "1  They split up to enclose around me.  Crap.  Wh...  \n",
       "2  Where's Bing?  Why aren't any of your roommate...  \n",
       "3  Question Vote (it really helps I know) Copyrig...  \n",
       "4  I want to marry Miss, I need your blessing.  Y...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.11 ms, sys: 0 ns, total: 2.11 ms\n",
      "Wall time: 1.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stories_df = pd.read_csv(\n",
    "    'data/src/stories.tsv',\n",
    "    sep='\\t',\n",
    "    names=['story_id', 'chapter_id', 'chapter_index', 'chapter_text'],\n",
    "    chunksize=CHUNK_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.io.parsers.TextFileReader"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stories_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_sss = wn.synsets('need')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('need.n.01'),\n",
       " Synset('need.n.02'),\n",
       " Synset('motivation.n.01'),\n",
       " Synset('indigence.n.01'),\n",
       " Synset('necessitate.v.01'),\n",
       " Synset('want.v.02'),\n",
       " Synset('need.v.03')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a condition requiring relief\n",
      "1 anything that is necessary but lacking\n",
      "2 the psychological feature that arouses an organism to action toward a desired goal; the reason for the action; that which gives purpose and direction to behavior\n",
      "3 a state of extreme poverty or destitution\n",
      "4 require as useful, just, or proper\n",
      "5 have need of\n",
      "6 have or feel a need for\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(need_sss)):\n",
    "    print(i, need_sss[i].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_ss = need_sss[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_lemmas = need_ss.lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['motivation', 'motive', 'need']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_hyponyms = need_ss.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('ethical_motive.n.01'),\n",
       " Synset('irrational_motive.n.01'),\n",
       " Synset('life.n.13'),\n",
       " Synset('psychic_energy.n.01'),\n",
       " Synset('rational_motive.n.01'),\n",
       " Synset('urge.n.01')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('conscience.n.01'),\n",
       " Synset('hedonism.n.01'),\n",
       " Synset('inner_light.n.01')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_hyponyms[0].hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_hyponyms_all = list(need_ss.closure(lambda x: x.hyponyms()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('eat.v.01') take in solid food\n",
      "Synset('eat.v.02') eat a meal; take a meal\n",
      "Synset('feed.v.06') take in food; used of animals only\n",
      "Synset('eat.v.04') worry or cause anxiety in a persistent way\n",
      "Synset('consume.v.05') use up (resources or materials)\n",
      "Synset('corrode.v.01') cause to deteriorate due to the action of water, air, or an acid\n"
     ]
    }
   ],
   "source": [
    "for x in wn.synsets('eat'):\n",
    "    print(x, x.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('food.n.01'), Synset('substance.n.07'), Synset('matter.n.03'), Synset('physical_entity.n.01'), Synset('entity.n.01')]\n",
      "[Synset('provide.v.02'), Synset('give.v.03'), Synset('transfer.v.05')]\n",
      "[Synset('provide.v.02'), Synset('give.v.03'), Synset('transfer.v.05')]\n",
      "[Synset('supply.v.01'), Synset('give.v.03'), Synset('transfer.v.05')]\n",
      "[Synset('insert.v.02'), Synset('put.v.01'), Synset('move.v.02')]\n",
      "[Synset('promote.v.01'), Synset('support.v.01')]\n",
      "[Synset('consume.v.02')]\n",
      "[Synset('provide.v.02'), Synset('give.v.03'), Synset('transfer.v.05')]\n",
      "[Synset('move.v.03')]\n",
      "[Synset('exploit.v.01'), Synset('use.v.01')]\n",
      "[Synset('regale.v.01'), Synset('provide.v.02'), Synset('give.v.03'), Synset('transfer.v.05')]\n",
      "[Synset('enrich.v.01'), Synset('better.v.02'), Synset('change.v.01')]\n",
      "[Synset('give.v.08')]\n"
     ]
    }
   ],
   "source": [
    "for x in wn.synsets('feed'):\n",
    "    hypers = list(x.closure(lambda x: x.hypernyms(), depth=-1))\n",
    "    print(hypers)\n",
    "    if need_ss in hypers:\n",
    "        print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('consume.v.02'), Synset('eat.v.02')]\n",
      "[Synset('consume.v.02')]\n",
      "[Synset('consume.v.02')]\n",
      "[Synset('worry.v.03')]\n",
      "[Synset('spend.v.02')]\n",
      "[Synset('damage.v.01')]\n"
     ]
    }
   ],
   "source": [
    "for x in wn.synsets('eat'):\n",
    "    hypers = list(x.closure(lambda x: x.hypernyms(), depth=1))\n",
    "    print(hypers)\n",
    "    if need_ss in hypers:\n",
    "        print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_ss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('ethical_motive.n.01'),\n",
       " Synset('irrational_motive.n.01'),\n",
       " Synset('life.n.13'),\n",
       " Synset('psychic_energy.n.01'),\n",
       " Synset('rational_motive.n.01'),\n",
       " Synset('urge.n.01'),\n",
       " Synset('conscience.n.01'),\n",
       " Synset('hedonism.n.01'),\n",
       " Synset('inner_light.n.01'),\n",
       " Synset('compulsion.n.02'),\n",
       " Synset('irrational_impulse.n.01'),\n",
       " Synset('mania.n.01'),\n",
       " Synset('incitement.n.03'),\n",
       " Synset('libidinal_energy.n.01'),\n",
       " Synset('disincentive.n.01'),\n",
       " Synset('incentive.n.01'),\n",
       " Synset('reason.n.01'),\n",
       " Synset('abience.n.01'),\n",
       " Synset('adience.n.01'),\n",
       " Synset('death_instinct.n.01'),\n",
       " Synset('wanderlust.n.01'),\n",
       " Synset('sense_of_shame.n.01'),\n",
       " Synset('superego.n.01'),\n",
       " Synset('wee_small_voice.n.01'),\n",
       " Synset('onomatomania.n.01'),\n",
       " Synset('compulsion.n.01'),\n",
       " Synset('agromania.n.01'),\n",
       " Synset('dipsomania.n.01'),\n",
       " Synset('egomania.n.01'),\n",
       " Synset('kleptomania.n.01'),\n",
       " Synset('logorrhea.n.01'),\n",
       " Synset('monomania.n.01'),\n",
       " Synset('necrophilia.n.01'),\n",
       " Synset('phaneromania.n.01'),\n",
       " Synset('pyromania.n.01'),\n",
       " Synset('trichotillomania.n.01'),\n",
       " Synset('signal.n.02'),\n",
       " Synset('acathexis.n.01'),\n",
       " Synset('cathexis.n.01'),\n",
       " Synset('moral_force.n.01'),\n",
       " Synset('occasion.n.03'),\n",
       " Synset('score.n.05'),\n",
       " Synset('why.n.01')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_hyponyms_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wattpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    for p in punctuation:\n",
    "        text = text.replace(p, '')\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window_generator(seq, size, step):\n",
    "    print(len(seq))\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), step) if len(seq) - pos > step or len(seq) < size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example = \"\"\"\n",
    "Hands Across Hawthorne was a rally held at the Hawthorne Bridge in the American West Coast city of Portland, Oregon, on May 29, 2011. The demonstration was in response to an attack, one week earlier, on Brad Forkner and Christopher Rosevear, a gay male couple who had been holding hands while walking across the bridge. According to the couple and the Portland Police Bureau, a group of five men followed Forkner and Rosevear along the bridge before physically assaulting them. The assault was condemned by Portland's mayor, Sam Adams, and its police chief, Mike Reese, and news of the attack spread throughout the Pacific Northwest and the United States. The attack prompted volunteers from the Q Center, a nonprofit organization that supports the LGBT community, to form street patrols as a means of monitoring Portland's downtown area.\n",
    "Several LGBT and human rights organizations sponsored Hands Across Hawthorne in response to the attack, with the purpose of linking hands across the entire span of the Hawthorne Bridge to show solidarity. More than 4,000 people attended the rally, which had been publicized on a single Facebook page 72 hours previously. Forkner, Rosevear, Mayor Adams, and other community leaders spoke at the rally. The event received attention throughout the United States. On June 5, residents of Spokane, Washington, held a similar hand-holding rally called \"Hands Across Monroe\", crossing the Monroe Street Bridge in Riverfront Park.\n",
    "\"\"\"\n",
    "\n",
    "def extract_information(text, window_size=50, step=25):\n",
    "    info = {\n",
    "        'needs': None, # LDA diciendole lo que tiene que encontrar\n",
    "        'behaviours': None, \n",
    "    }\n",
    "    text = clean_text(text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [w for w in words if w not in stopwords.words('english')]\n",
    "    windows = window_generator(words, window_size, step)\n",
    "#     for window in windows:\n",
    "        \n",
    "    return list(windows)\n",
    "   \n",
    "# extract_information(example, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hands Across Hawthorne was a rally held at the Hawthorne Bridge in the American\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['hands',\n",
       "  'across',\n",
       "  'hawthorne',\n",
       "  'rally',\n",
       "  'held',\n",
       "  'hawthorne',\n",
       "  'bridge',\n",
       "  'american'],\n",
       " ['hawthorne', 'bridge', 'american']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = ' '.join(example.split()[:14])\n",
    "print(ex)\n",
    "extract_information(ex, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/out/lda_winners.txt', 'w') as f:\n",
    "    pass\n",
    "f.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA topic extraction, guiding the process with our specific keywords\n",
    "# Result: topic list, list of words and frequencies\n",
    "needs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Graph\n",
    "behaviors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/antonio/.virtualenvs/wattpad/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antonio/.virtualenvs/wattpad/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mget_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antonio/.virtualenvs/wattpad/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    980\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antonio/.virtualenvs/wattpad/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1717\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas/_libs/parsers.c:10862)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas/_libs/parsers.c:11343)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas/_libs/parsers.c:11884)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows (pandas/_libs/parsers.c:11755)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error (pandas/_libs/parsers.c:28765)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for chunk in stories_df:\n",
    "    for text in chunk.chapter_text:\n",
    "        text = clean_text(text)\n",
    "        words = word_tokenize(text)\n",
    "        words = [w for w in words if w not in stopwords.words('english')]\n",
    "        windows = window_generator(words, window_size, step)\n",
    "        for window in windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984493"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c=0\n",
    "# for chunk in stories_df:\n",
    "#     for i, x in chunk.iterrows():\n",
    "#         c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3947664"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c\n",
    "# 3947664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# c=0\n",
    "# for chunk in stories_df:\n",
    "#     if c > 0:\n",
    "#         break\n",
    "#     display(chunk)\n",
    "#     c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Comprobar que pasa si el texto es menor que el window_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
